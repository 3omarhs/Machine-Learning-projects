# -*- coding: utf-8 -*-
"""Advanced_AI_project2_(2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MB1jfQjRruG23t9Vmip1egyNuv4CXOga
"""

# https://www.tensorflow.org/api_docs/python/tf/keras/datasets >> datasets in tf.keras

import tensorflow as tf
from matplotlib import pyplot as plt
import numpy as np

objects =  tf.keras.datasets.mnist
(training_images, training_labels), (test_images, test_labels) = objects.load_data()

print(f'training_images: {training_images.shape}')  # Number of pixels
print(f'training_labels: {training_labels.shape}')  # Number of pixels
print(f'test_images: {test_images.shape}')  # Number of pixels
print(f'test_labels: {test_labels.shape}')  # Number of pixels

print(training_images.shape)
# print(training_images[0])
plt.imshow(test_images[56])

training_images  = training_images / 255.0    ## لتحويل القيم بين الصفر والواحد
test_images = test_images / 255.0

model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),  # over the 2D input data,  kernel_size: حجم الـfilter, activation: Activation function(decide iof neuron is important or not)
                                    tf.keras.layers.MaxPooling2D((2,2)),  # pooling (highest pixel in selected square & take its value..)
                                    # tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),
                                    # tf.keras.layers.MaxPooling2D((2,2)),
                                    tf.keras.layers.Flatten(),   # multi-dimensional tensors to single dimension.
                                    tf.keras.layers.Dense(128, activation='relu'),  # deep connected NN layer (HL)
                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])  # output layer / sum(prob. of each neurons) = 1

model.compile(optimizer = 'adam',  # AI Algorithm used
              loss = 'sparse_categorical_crossentropy',  # scalar value (error) that we attempt to minimize during our training of the model, sparse_categorical_crossentropy: Training a neural network involves passing data forward, through the model, and comparing predictions with ground truth labels
              metrics=['accuracy'])  # shown variable during each epoch in model training.

model.fit(training_images, training_labels, epochs=50)

model.evaluate(test_images, test_labels)   # Acuracy of testing.

# print(model.evaluate(test_images,test_labels))  ## find model accuracy
print(np.argmax(model.predict(test_images)[56]))  # return max element of the array.

labels_test = []
labels_train = []
for i in range(10):
  labels_test.append(np.argmax(model.predict(test_images)[i]))
  labels_train.append(np.argmax(model.predict(training_images)[i]))
print(f'Testing: {labels_test}')
print(f'Training: {labels_train}')

plt.figure(figsize=(10,7))
plt.scatter(test_labels[:10]+0.1, labels_test , c='b', label="testing data")
# print(training_labels[:10])
# print(labels_train)
plt.scatter(training_labels[:10], labels_train , c='r', label="training data")
plt.legend()

test_Image = 56
plt.imshow(test_images[test_Image])
prediction=model.predict(test_images)
print(np.argmax(prediction[test_Image]))

tf.keras.utils.plot_model(model, show_shapes=True)

model.summary()